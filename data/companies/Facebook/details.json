{"id":"Facebook","basicInformation":"<p><span class=\"font-bold\">Domicile</span>: United States</p><p><span class=\"font-bold\">Website</span>:<a href=\"https://www.facebook.com\">www.facebook.com</a></p>","keyFindings":"<p>In 2020, Facebook announced a range of rules around misinformation and election interference, focused on limiting the weaponization of its platforms during the 2020 U.S. election cycle. In the U.S., it faced a record <a href=\"https://www.nytimes.com/2019/07/12/technology/facebook-ftc-fine.html\">$5 billion penalty</a>from the U.S. Federal Trade Commission (FTC) for privacy violations, intense <a href=\"https://www.cnet.com/news/tech-titans-hammered-by-congress-in-historic-antitrust-hearing/\">antitrust scrutiny</a>, and a major <a href=\"https://www.npr.org/2020/07/01/885853634/big-brands-abandon-facebook-threatening-to-derail-a-70b-advertising-juggernaut\">ad boycott</a>protesting its lackluster enforcement of its policies on hate speech and incitement to violence. Although the company introduced engaged in some accountability processes involving independent experts, including the Facebook Oversight Board, the turbulence of 2020 only led to marginal progress in all three categories of the RDR Index.</p><p>Our research in 2020 found that:<br></p><ul>\n  <li><span class=\"font-bold\">Facebook made little slow progress on human rights due diligence </span>through both the provisions of its settlement with the FTC and its <a href=\"https://about.fb.com/news/2020/07/civil-rights-audit-report/\">third-party civil rights audit</a>, but did not show clear evidence that it conducts human rights impact assessments of its own policy enforcement, targeted advertising, algorithmic systems, and zero rating (G4b-e).</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Facebook&#x2019;s transparency on its policy enforcement has stalled</span>. The company&#x2019;s transparency and enforcement reports now cover Instagram in addition to Facebook, but the reports offer only fragmented data on content and account restrictions (F4a, F4b) and no data on advertising policy enforcement (F4c).</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Facebook&#x2019;s algorithmic transparency is poor. </span>It published a policy (F1d) describing how its flagship social media service uses algorithmic systems, but offered no policy on how it develops them (P1b). The information it published on how it uses algorithms in areas such as appeals (G6b) and ranking systems (F12) was opaque..</li>\n</ul>","analysis":"<ul>\n  <li>Under its settlement with the U.S. Federal Trade Commission (FTC), Facebook committed to undertaking independent assessments of the impact of its enforcement decisions on privacy (G4b).</li>\n  <li>Facebook removed previous versions of the Terms of Service for Facebook and Messenger from its website (F2a).</li>\n  <li>Facebook made it less clear whether the company deletes all user information after a user terminates their account (P6).</li>\n  <li>Facebook improved its security policies by clarifying protocols for preventing unauthorized employee access published more information about its internal systems for keeping user information secure, guarding against employee access to user data (P13) and committing to notifying users in cases of data breaches if it removes an app for misusing user data (P15)</li>\n</ul>","keyRecommendation":"<ul>\n  <li>Facebook should explicitly address the impacts of its own policy enforcement, targeted advertising practices, algorithmic use and development, and zero-rating partnerships through robust human rights impact assessments (G4).</li>\n  <li>Facebook should significantly improve its transparency reporting on how it enforces its own content policies. Reports should be organized by country, type of restriction, and content type. Facebook should describe the role of algorithms in the policy enforcement process, and publish data on its ad policy enforcement (F4a-c).</li>\n  <li>Facebook should explicitly commit to following international human rights standards in developing and using algorithms (G1) and publish information about how they are developed and used across its operations (F1d, P1b).</li>\n</ul>","governance":"<p>Facebook had the third highest governance score among digital platforms, but fell short in several areas, notably its transparency on human rights impact assessments and content moderation appeals.</p><ul>\n  <li><span class=\"font-bold\">Commitment to human rights: </span>Facebook made broad commitments both freedom of expression, freedom of information, and privacy, but it did not explicitly apply them to the development and use of algorithms (G1).</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Stakeholder engagement: </span>As a member of the multi-stakeholder <a href=\"http://globalnetworkinitiative.org/\">Global Network Initiative</a>, Facebook underwent an <a href=\"https://globalnetworkinitiative.org/wp-content/uploads/2020/04/2018-2019-PAR.pdf\">independent assessment</a>of its implementation of the human rights-based GNI Principles in 2018/19 (G5).</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Human rights due diligence: </span>Facebook conducted or commissioned robust assessments of human rights impacts related to the regulatory environments in which it operates, releasing summaries of three of them in 2020 (G4a). But the company was much less transparent about how it assesses the impact of its own policy enforcement (G4b), targeted advertising practices (G4c), use and development of algorithms (G4d), and its zero-rating agreements, including Free Basics (G4e). It was the only company to demonstrate some form of impact assessment on its targeted advertising practices (G4c) through its third-party civil rights audit. It showed further progress through its agreement with the FTC, under which Facebook is obligated to assess the impact of its privacy policies and practices on its users.</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Remedy: </span>Facebook disclosed little about its broader offered little transparency regarding its remedy procedures mechanisms for freedom of expression and privacy grievances (G6a). But it scored the highest of any digital platform on content moderation appeals (G6b), thanks to relatively strong policies describing its appeals mechanisms for both Facebook and Instagram.</li>\n</ul>","freedom":"<p><br>Facebook published some information about its processes for policy enforcement and responding to demands for content and account removal, but this was offset by incomplete data demonstrating the actual enforcement of its policies and scarce information on how the company uses algorithms.</p><ul>\n  <li><span class=\"font-bold\">Content moderation: </span>Facebook&#x2019;s content rules were easy to find and understand (F1a), but it fell short of committing to notify its users of policy changes and removed previous versions of its terms for Facebook and Messenger from its website (F2a). Facebook had strong disclosure on what content is prohibited and how it enforces its content rules (F3a). The company published quarterly <a href=\"https://transparency.facebook.com/community-standards-enforcement\">enforcement reports</a>, but these reports conflated different restriction types and failed to disclose figures by country, among other shortcomings (F4a, b). Its bot policy was also unclear in several places, including details on how it is enforced (F13).</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Algorithmic use and content curation: </span>Facebook published a policy covering some of the ways it uses algorithms on its flagship social networking platform.This policy&#x2014;the <a href=\"https://www.facebook.com/business/help/718033381901819\">News Feed Publisher Principle Guidelines</a>&#x2014;was difficult for non-business users to find, and we found no similar policies for its other services (F1d). Facebook also disclosed information on how it uses algorithms to curate, rank, or recommend content on Facebook and Instagram, but the exact scope of these ranking algorithms was unclear (F12)<span class=\"font-bold\">.</span></li>\n</ul><ul>\n  <li><span class=\"font-bold\">Advertising content and targeting: </span>Facebook&#x2019;s <a href=\"https://www.facebook.com/policies/ads/\">ad content policies</a>were relatively easy to access (F1b), though its targeting rules were scattered across numerous policiesy documents (F1c). While the company published information about its ad content and targeting rules (F3b, c), these disclosures were opaque in several places, notably the role of algorithms in the ad review process. Facebook published no data about the enforcement of its ad policies (F4c).</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Censorship demands</span>: Facebook continued to disclose <a href=\"https://transparency.facebook.com/content-restrictions\">comprehensive information</a>on how it responds to government demands to restrict content or accounts on Facebook and Instagram, though we could find no parallel disclosure for WhatsApp or Messenger (F5a). Yet the company failed to adequately disclose data about these demands, notably by only reporting those with which it complied rather than those it received (F6). The company published incomplete information about how it responds to private requests to restrict content (F5b) on Facebook and Instagram (F7).</li>\n</ul>","privacy":"<p><br>Facebook&#x2019;s privacy scores were bolstered by strong disclosures about government demands for user information and slight improvements on security, but the company still lagged behind nearly all of its U.S. peers.</p><ul>\n  <li><span class=\"font-bold\">Handling of user data: </span>Facebook&#x2019;s privacy policies across all ranked services were easy to find and understand (P1a), although these policies did not all of them failed to clearly commit to adequately describe how the company notifiyinges users of changes prior to their coming into effect (P2a). We found no operational-level policy on how user information and other data are used to develop and train algorithms (P1b). The company also failed to adequately describe how it collects and makes use of user data. Facebook also did not disclose whether users can control how their data is collected and inferred (P7) and it did not describe whether or how it acquires and uses third-party data through non-technical means (P9).</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Government and private demands for user data: </span>Facebook disclosed comprehensive information about its process for responding to government demands for user information (P10a). It also released data on these requests, but this data is underreported in several areas and only some of these deficiencies can be attributed to legal restrictions (P11a). The company disclosed nothing about its processes for responding to private requests and published no data about these requests (P10b, P11b).</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Security: </span>Facebook revealed more information about its security policies in the two areas where its performance has historically been weak relative to many of its peers: security oversight (P13) and responding to data breaches (P15). These improvements align with its the terms of its <a href=\"https://www.ftc.gov/news-events/press-releases/2019/07/ftc-imposes-5-billion-penalty-sweeping-new-privacy-restrictions\">2019 settlement with the FTC</a>, under which Facebook was requiring Facebook ed to implement stronger security measures, including create a comprehensive data security program, monitor third-party app developers, and implement safeguards to limiting employee access to user data.</li>\n</ul>","footnotes":"footnotes missing"}